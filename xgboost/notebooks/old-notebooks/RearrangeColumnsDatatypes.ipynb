{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redfining features' data-types.  \n",
    "  \n",
    "After some exploration on the dataset I noticed the following :  \n",
    "- All values are set to float even the categorical and boolean.\n",
    "- Some of the categorical features are boolean features ( two categories 0 and 1).\n",
    "- Some of the continues features could be categorized as they have a few number of distinct values.\n",
    "\n",
    "----\n",
    "\n",
    "So what I'm going to do is to define a new data-set with some changes :  \n",
    "- analyse each feature and categorize it either [ continues, boolean or categorical ].\n",
    "- change features names to the format ps_(_cat, bin or cont)_...the rest of the old name ..., the reason for that is to make it easier to find the feature's category using the numpy.str.startwith().\n",
    "- I'll consider any feature with less than 30  distinct value to be categorical otherwise it's continues.\n",
    "- Also I'll change the data-type of them to be [ float for continues, bool for boolean and integer for categorical]\n",
    "- change the values of categorical items to be in range [ 0, number_of_distinct_values_for_this_feature ].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get lists of features names by their data-type. [ [cont]inues and [cat]egorical ]\n",
    "counter = 0;\n",
    "datatypes = {\n",
    "    'cont' : [],\n",
    "    'cat' : []\n",
    "}\n",
    "\n",
    "def setDatatypes(d) :\n",
    "    global counter\n",
    "    title = train.columns[counter]\n",
    "    counter +=1;\n",
    "    if title in ['target','id'] : return\n",
    "    distictValues = d.value_counts().shape[0]\n",
    "    \n",
    "    if distictValues <= 30 :\n",
    "        datatypes['cat'].append(title)\n",
    "    else :\n",
    "        datatypes['cont'].append(title)\n",
    "        \n",
    "_ = train.apply(setDatatypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def change_title(old_title, dtype) :\n",
    "    '''\n",
    "    change feature title in newData to format ps_(cat|cont)_.....\n",
    "    '''\n",
    "    pattern = re.compile('^(ps_)([a-z]{3,4}_[0-9]{1,2})')\n",
    "    t = pattern.findall(old_title)[0]\n",
    "    if len(t) == 2 :\n",
    "        new_title = t[0] + dtype + '_' + t[1]\n",
    "        train.rename(columns={title:new_title}, inplace=True)\n",
    "        test.rename(columns={title:new_title}, inplace=True)\n",
    "\n",
    "#-----------------------------------------------------------------------------------\n",
    "for title in datatypes['cat'] :\n",
    "    categories = train[title].append(test[title]).value_counts().index.values\n",
    "    categories.sort()\n",
    "    train[title] = pd.Categorical(train[title]).codes\n",
    "    test[title]  = pd.Categorical(test[title]).codes\n",
    "    change_title(title, 'cat')\n",
    "#--------------------------------------------------------------------------------------\n",
    "for title in datatypes['cont'] :\n",
    "    change_title(title, 'cont')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________________\n",
      "\n",
      "categorical columns with number of categories :\n",
      "\n",
      "ps_cat_ind_01  :\t8\n",
      "ps_cat_ind_02  :\t5\n",
      "ps_cat_ind_03  :\t12\n",
      "ps_cat_ind_04  :\t3\n",
      "ps_cat_ind_05  :\t8\n",
      "ps_cat_ind_06  :\t2\n",
      "ps_cat_ind_07  :\t2\n",
      "ps_cat_ind_08  :\t2\n",
      "ps_cat_ind_09  :\t2\n",
      "ps_cat_ind_10  :\t2\n",
      "ps_cat_ind_11  :\t2\n",
      "ps_cat_ind_12  :\t2\n",
      "ps_cat_ind_13  :\t2\n",
      "ps_cat_ind_14  :\t5\n",
      "ps_cat_ind_15  :\t14\n",
      "ps_cat_ind_16  :\t2\n",
      "ps_cat_ind_17  :\t2\n",
      "ps_cat_ind_18  :\t2\n",
      "ps_cat_reg_01  :\t10\n",
      "ps_cat_reg_02  :\t19\n",
      "ps_cat_car_01  :\t13\n",
      "ps_cat_car_02  :\t3\n",
      "ps_cat_car_03  :\t3\n",
      "ps_cat_car_04  :\t10\n",
      "ps_cat_car_05  :\t3\n",
      "ps_cat_car_06  :\t18\n",
      "ps_cat_car_07  :\t3\n",
      "ps_cat_car_08  :\t2\n",
      "ps_cat_car_09  :\t6\n",
      "ps_cat_car_10  :\t3\n",
      "ps_cat_car_11  :\t5\n",
      "ps_cat_car_15  :\t15\n",
      "ps_cat_calc_01  :\t10\n",
      "ps_cat_calc_02  :\t10\n",
      "ps_cat_calc_03  :\t10\n",
      "ps_cat_calc_04  :\t6\n",
      "ps_cat_calc_05  :\t7\n",
      "ps_cat_calc_06  :\t11\n",
      "ps_cat_calc_07  :\t10\n",
      "ps_cat_calc_08  :\t12\n",
      "ps_cat_calc_09  :\t8\n",
      "ps_cat_calc_10  :\t26\n",
      "ps_cat_calc_11  :\t21\n",
      "ps_cat_calc_12  :\t11\n",
      "ps_cat_calc_13  :\t16\n",
      "ps_cat_calc_14  :\t25\n",
      "ps_cat_calc_15  :\t2\n",
      "ps_cat_calc_16  :\t2\n",
      "ps_cat_calc_17  :\t2\n",
      "ps_cat_calc_18  :\t2\n",
      "ps_cat_calc_19  :\t2\n",
      "ps_cat_calc_20  :\t2\n",
      "___________________________\n",
      "\n",
      "continues columns with number of distinct values :\n",
      "\n",
      "ps_cont_reg_03  :\t5077\n",
      "ps_cont_car_11  :\t104\n",
      "ps_cont_car_12  :\t214\n",
      "ps_cont_car_13  :\t104192\n",
      "ps_cont_car_14  :\t905\n"
     ]
    }
   ],
   "source": [
    "print \"___________________________\\n\"\n",
    "print \"categorical columns with number of categories :\\n\"\n",
    "for i in [ [col, train[col].append(test[col]).value_counts().shape[0]]\\\n",
    "          for col in train.columns if col.startswith('ps_cat') ] :\n",
    "    \n",
    "    print i[0], \" :\\t\", i[1]\n",
    "print \"___________________________\\n\"\n",
    "print \"continues columns with number of distinct values :\\n\"\n",
    "for i in [ [col, train[col].append(test[col]).value_counts().shape[0]]\\\n",
    "          for col in train.columns if col.startswith('ps_cont') ] :\n",
    "    \n",
    "    print i[0], \" :\\t\", i[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# save data to disk\n",
    "#train.to_csv('./data/new_train.csv',index=False)\n",
    "#test.to_csv('./data/new_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define OneHotEncoder classifier.\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pickle\n",
    "encoders = []\n",
    "cat = [ feature for feature in train.columns if feature.startswith('ps_cat') ]\n",
    "for feature in cat :\n",
    "        enc = OneHotEncoder(sparse=False)\n",
    "        _ = enc.fit(train[feature].append(test[feature]).values.reshape(-1,1))\n",
    "        encoders.append(enc)\n",
    "    \n",
    "with open('./data/OneHotEncoder.clf', 'wb') as f:\n",
    "    pickle.dump(file=f, obj=encoders)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
