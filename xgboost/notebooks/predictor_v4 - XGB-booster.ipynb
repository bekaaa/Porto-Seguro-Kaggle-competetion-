{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as py\n",
    "\n",
    "import log\n",
    "\n",
    "%matplotlib inline\n",
    "seed = 0\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing training data.\n",
    "train_sample_size = 10000\n",
    "val_size = 3000\n",
    "\n",
    "train = np.load('../../nn/data/train_scaled.npy')\n",
    "\n",
    "#train = train[:train_sample_size,:]\n",
    "labels = train[:,0]   \n",
    "train = train[:,1:]\n",
    "\n",
    "zero_important_features = [3, 5, 15, 22, 23, 24, 25, 26, 35, 39, 45, 48, 49, 56, 57, 58, 59, 60,\\\n",
    "                           62, 68, 71, 72, 73, 74, 79, 80, 83, 88, 91, 94, 95, 96, 97, 118, 119, 120]\n",
    "\n",
    "above_0_important_features = [ i for i in range(train.shape[1]) if i not in zero_important_features ]\n",
    "train = train[:, above_0_important_features]\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(train,labels,random_state=seed,test_size=val_size)\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "dvalid = xgb.DMatrix(x_valid, label=y_valid)\n",
    "\n",
    "del train, labels, x_train, x_valid, y_train, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing test data.\n",
    "if 0 :\n",
    "    test = np.load('../../nn/data/test_scaled.npy')\n",
    "    test = test[:, above_0_important_features]\n",
    "    dtest = xgb.DMatrix(test)\n",
    "    del test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining Gini's Score function.\n",
    "def gini(labels, preds) :\n",
    "    return roc_auc_score(labels, preds) * 2. - 1\n",
    "#----------------------------\n",
    "def gini_xgb(preds, dtrain):\n",
    "    return [('gini', gini(dtrain.get_label(), preds))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = bla[3].cvfold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.evaluation_result_list[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-6c7e3c1c990b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert p not in params.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Automated Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROUNDS = 400\n",
    "ESROUNDS = 30\n",
    "\n",
    "params = {\n",
    "    'max_delta_step' : 0,\n",
    "    'scale_pos_weight' : 5.3, #1,\n",
    "    \n",
    "    'max_depth' : 10,\n",
    "    'min_child_weight' : 7,\n",
    "    \n",
    "    'subsample' : 0.9,\n",
    "    'colsample_bytree' : 0.5,\n",
    "    \n",
    "    'reg_alpha' : 5,\n",
    "    'reg_lambda' : 0.0001,\n",
    "    \n",
    "    'gamma' : 0,\n",
    "    \n",
    "    'eta' : 0.1,\n",
    "    \n",
    "    'objective' : \"binary:logistic\",\n",
    "    'n_jobs' : -1,\n",
    "    'eval_metric' : 'auc',\n",
    "    'random_seed' : seed\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetBestCVFolds : \n",
    "    def __init__(self) :\n",
    "        #self.cvfolds = cvfolds\n",
    "        self.best_score = -1\n",
    "    def __call__(self, cbenv) :\n",
    "        current_score = cbenv.evaluation_result_list[1][1]\n",
    "        if current_score > self.best_score :\n",
    "            self.best_score = current_score\n",
    "            global cvfolds\n",
    "            cvfolds = cbenv.cvfolds\n",
    "cvfolds = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fpreproc(dtrain_, dtest_, param_):\n",
    "    label = dtrain_.get_label()\n",
    "    ratio = float(np.sum(label == 0)) / np.sum(label == 1)\n",
    "    param_['scale_pos_weight'] = ratio\n",
    "    return (dtrain_, dtest_, param_)\n",
    "\n",
    "def step_cv(names, values) : \n",
    "    \n",
    "    for p,v in zip(names, values) :\n",
    "        if p not in params.keys() :\n",
    "            raise \"Error %s not in parameters\" % p\n",
    "        params[p] = v\n",
    "    \n",
    "    t = np.datetime64('now')\n",
    "    global cvfolds\n",
    "    cvfolds = None\n",
    "    \n",
    "    cv_results = xgb.cv(params, dtrain, \n",
    "                    num_boost_round=ROUNDS, early_stopping_rounds=ESROUNDS, seed=seed,\n",
    "                    nfold=3, stratified = True,\n",
    "                    metrics=('auc'),\n",
    "                    fpreproc=fpreproc,\n",
    "                    verbose_eval = False,\n",
    "                    callbacks=[GetBestCVFolds()]\n",
    "                    )\n",
    "    #-----------------------\n",
    "    assert cvfolds != None\n",
    "    val_preds = np.zeros(dvalid.num_row())\n",
    "    for fold in cvfolds :\n",
    "        val_preds += fold.bst.predict(dvalid)\n",
    "    val_preds /= len(cvfolds)\n",
    "    val_score = gini(dvalid.get_label(), val_preds)\n",
    "    #--------------------------------------\n",
    "    return (np.max(cv_results['test-auc-mean']),\n",
    "            np.max(cv_results['train-auc-mean']),\n",
    "            np.argmax(cv_results['test-auc-mean']),\n",
    "            (np.datetime64('now') - t).astype('int') / 60.,\n",
    "            val_score\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_params(names, values) :\n",
    "    best_sc = -1\n",
    "    log.msg('**** Grid Start *********')\n",
    "    \n",
    "    for grid in values :\n",
    "        \n",
    "        msg = \"CV with \"\n",
    "        for i,v in enumerate(grid):\n",
    "            msg+= \"%s = %g, \" % (names[i], v)\n",
    "        log.msg(msg)\n",
    "        \n",
    "        train_sc, test_sc, n_trees, step_time, val_sc = step_cv(names, grid)\n",
    "        \n",
    "        log.msg('train score : %g, fold-dev score : %g, val score : %g, n_trees : %d,'\\\n",
    "                'step time : %.1f minutes'\\\n",
    "               % (train_sc, test_sc, val_sc, n_trees, step_time) )\n",
    "        \n",
    "        #if test_sc > best_score or (test_sc == best_score and train_sc > best_train) :\n",
    "        if val_sc > best_sc :\n",
    "            best_sc = val_sc\n",
    "            best_train = train_sc\n",
    "            best_test = test_sc\n",
    "            best_n_trees = n_trees\n",
    "            best_params = grid\n",
    "            \n",
    "    #best_gini = (best_score * 2) - 1\n",
    "    \n",
    "    log.msg('****** End of grid *********')\n",
    "    msg =   'best val score : %g, '\\\n",
    "            'best test score : %g, '\\\n",
    "            'best train score : %g, '\\\n",
    "            'best n_trees = %d, '\\\n",
    "           % ( best_sc, best_test, best_train, best_n_trees )\n",
    "    for i,v in enumerate(best_params) :\n",
    "        msg += 'best %s = %g, ' % (names[i], v)\n",
    "    log.msg(msg)\n",
    "    print msg\n",
    "    \n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvfolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.LOG_PATH = './logs/'\n",
    "try :\n",
    "    log.close()\n",
    "except :\n",
    "    pass\n",
    "log.init('tuning_params-5.log')\n",
    "    \n",
    "log.msg('------------------initialized-----------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = ('s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(n) == tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------\n",
    "# Adjusting unbalanced data. [max_delta_step, scale_pos_weight]\n",
    "#--------------------------------------------------------------\n",
    "names = ('max_delta_step', 'scale_pos_weight')\n",
    "grid_params = [\n",
    "    (max_delta_step, scale_pos_weight)\n",
    "    for max_delta_step in [ 0 ]\n",
    "    for scale_pos_weight in [1] #np.arange(4.9,6,.2)  #[ 4, 5, 6, 7, 8 ]   #[26, 1, 1.5, 2, 5, 10]\n",
    "]\n",
    "best_delta_step, best_pos_weight = tune_params(names, grid_params)\n",
    "##################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------\n",
    "# Adjusting unbalanced data. [max_delta_step, scale_pos_weight]\n",
    "#--------------------------------------------------------------\n",
    "names = ('max_delta_step', 'scale_pos_weight')\n",
    "grid_params = [\n",
    "    (max_delta_step, scale_pos_weight)\n",
    "    for max_delta_step in [ 0 ]\n",
    "    for scale_pos_weight in [1] #np.arange(4.9,6,.2)  #[ 4, 5, 6, 7, 8 ]   #[26, 1, 1.5, 2, 5, 10]\n",
    "]\n",
    "best_delta_step, best_pos_weight = tune_params(names, grid_params)\n",
    "##################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------\n",
    "names = ('max_depth', 'min_child_weight')\n",
    "grid_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in np.arange(1,10,2)\n",
    "    for min_child_weight in np.arange(1,10,2)\n",
    "]\n",
    "best_depth, best_child_weight = tune_params(names, grid_params)\n",
    "#####\n",
    "grid_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in [best_depth-1, best_depth, best_depth+1]\n",
    "    for min_child_weight in [best_child_weight-1, best_child_weight, best_child_weight+1]\n",
    "]\n",
    "best_depth, best_child_weight = tune2param(names, grid_params)\n",
    "#######\n",
    "if best_depth == 10 or best_child_weight == 10 :\n",
    "    if best_depth == 10 : max_depth_r = np.arange(10,17,2)\n",
    "    elif best_depth <10 : max_depth_r = [best_depth]\n",
    "    if best_child_weight == 10 : min_child_weight_r = np.arange(10,17,2)\n",
    "    elif best_child_weight < 10 : min_child_weight_r = [best_child_weight]\n",
    "    grid_params = [\n",
    "        (max_depth, min_child_weight)\n",
    "        for max_depth in max_depth_r\n",
    "        for min_child_weight in min_child_weight_r\n",
    "    ]\n",
    "    best_depth, best_child_weight = tune2param(names, grid_params)\n",
    "##########\n",
    "if best_depth > 10 or best_child_weight > 10 :\n",
    "    if best_depth > 10 : max_depth_r = [ best_depth-1, best_depth, best_depth+1 ]\n",
    "    else : max_depth_r = [best_depth]\n",
    "    if best_child_weight > 10 : \n",
    "        min_child_weight_r = [best_child_weight-1,best_child_weight,best_child_weight+1]\n",
    "    else : min_child_weight_r = [best_child_weight]\n",
    "    grid_params = [\n",
    "        (max_depth, min_child_weight)\n",
    "        for max_depth in max_depth_r\n",
    "        for min_child_weight in min_child_weight_r\n",
    "    ]\n",
    "    best_depth, best_child_weight = tune2param(names, grid_params)\n",
    "###########    \n",
    "params['max_depth'] = best_depth\n",
    "params['min_child_weight'] = best_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------------\n",
    "name = 'gamma'\n",
    "grid_params = np.arange(1,10,2)\n",
    "best_gamma = tune1param(name, grid_params)\n",
    "######\n",
    "grid_params = np.arange(best_gamma-1, best_gamma+1.1, 0.2)\n",
    "best_gamma = tune1param(name, grid_params)\n",
    "#######\n",
    "grid_params = np.arange(best_gamma-.1, best_gamma+.11, 0.1)\n",
    "best_gamma = tune1param(name, grid_params)\n",
    "########\n",
    "params['gamma'] = best_gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------\n",
    "name = 'max_delta_step'\n",
    "grid_params = [1,2]\n",
    "best_delta_step = tune1paramparam(ngrid_params_params grid_params)\n",
    "##########\n",
    "grid_params = np.arange(.1,1,.2)\n",
    "best_delta_step = tune1param(name, grid_params)\n",
    "##########\n",
    "#grid_params = [ best_params[0] - .1, best_params[0], best_params[0] + .1 ]\n",
    "grid_params = [best_delta_step - .1, best_delta_step, best_delta_step + .1]\n",
    "best_delta_step = tune1param(name, grid_params)\n",
    "###########\n",
    "params['max_delta_step'] = best_delta_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------------------------\n",
    "names = ('subsample', 'colsample_bytree')\n",
    "grid_params = [\n",
    "    (subsample, colsample_bytree)\n",
    "    for subsample in np.arange(.1,1,.2)\n",
    "    for colsample_bytree in np.arange(.1,1,.2)\n",
    "]\n",
    "best_subsample, best_colsample = tune2param(names, grid_params)\n",
    "\n",
    "grid_params = [\n",
    "    (subsample, colsample_bytree)\n",
    "    for subsample in np.arange(best_subsample-.1,best_subsample+.11, 0.05)\n",
    "    for colsample_bytree in np.arange(best_colsample-.1, best_colsample+.11, 0.05)\n",
    "]\n",
    "best_subsample, best_colsample = tune2param(names, grid_params)\n",
    "params['subsample'] = best_subsample\n",
    "params['col_sample_bytree'] = best_colsample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------------\n",
    "names = ('reg_alpha', 'reg_lambda')\n",
    "grid_params = [\n",
    "    (alpha, lambd)\n",
    "    for alpha in np.arange(1,10,2)\n",
    "    for lambd in [ 1 * 10 ** -i for i in [0,1,2,3,4] ]\n",
    "]\n",
    "best_alpha, best_lambd = tune2param(names, grid_params)\n",
    "######\n",
    "grid_params = [\n",
    "    (alpha, best_lambd)\n",
    "    for alpha in np.arange(best_alpha-1, best_alpha+1.1, 0.5)\n",
    "]\n",
    "best_alpha, best_lambd = tune2param(names, grid_params)\n",
    "##########\n",
    "params['reg_alpha'] = best_alpha\n",
    "params['reg_lambda'] = best_lambd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------------------\n",
    "name = 'eta'\n",
    "grid_params = [.1, .2, .3]\n",
    "best_eta = tune1param(name, grid_params)\n",
    "#######\n",
    "params['eta'] = best_eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Done tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Submision Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune1param('eta', [.1])\n",
    "#----------\n",
    "test_preds = []\n",
    "for p in test_preds_dict.values() :\n",
    "    if len(test_preds) == 0 :\n",
    "        test_preds = p\n",
    "    else :\n",
    "        test_preds += p\n",
    "test_preds /= len(test_preds_dict)\n",
    "#---------\n",
    "try :\n",
    "    _ = len(ids)\n",
    "except :\n",
    "    ids = np.load('../../nn/data/test_ids.npy')\n",
    "\n",
    "with open('../data/submission.csv', 'wb') as f :\n",
    "\tf.write('id,target')\n",
    "    \n",
    "\tfor i,p in zip(ids,test_preds) :\n",
    "\t\tf.write('\\n%d,%.4f'%(i,p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediction validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune1param('eta', [.1])\n",
    "dev_preds = []\n",
    "for p in dev_preds_dict.values() :\n",
    "    if len(dev_preds) == 0 :\n",
    "        dev_preds = p\n",
    "    else :\n",
    "        dev_preds += p\n",
    "dev_preds /= len(dev_preds_dict)\n",
    "print gini_xgb(dev_preds, dvalid)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
