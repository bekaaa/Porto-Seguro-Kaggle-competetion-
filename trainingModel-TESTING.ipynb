{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "seed = 2\n",
    "from xgboost import XGBClassifier\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = pd.read_csv('./data/new_train.csv')\n",
    "train = pd.read_csv('./data/train_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = int(1e4)\n",
    "try :\n",
    "    sample = train[train.target == 1].sample(n=sample_size/2, random_state=seed)\n",
    "    sample = sample.append( train[train.target == 0].sample(n=sample_size/2, random_state=seed))\n",
    "except ValueError :\n",
    "    sample = train[train.target == 1]\n",
    "    sample = sample.append( train[train.target == 0].sample(n=sample_size-21694, random_state=seed) )\n",
    "\n",
    "sample = sample.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "#sample.to_csv('./data/train_sample.csv', index=False)\n",
    "train = sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train.target\n",
    "train.drop(['target','id'], inplace=True, axis=1)\n",
    "train.drop([ col for col in train.columns if col.startswith('ps_cont') ],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/OneHotEncoder.clf', 'rb') as f:\n",
    "    encoders = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_train = None\n",
    "\n",
    "for feature,encoder in zip(train.columns,encoders) :\n",
    "    encoded = encoder.transform(train[feature].values.reshape(-1,1))\n",
    "    if enc_train is None :\n",
    "        enc_train = encoded\n",
    "    else :\n",
    "        enc_train = np.concatenate((enc_train, encoded), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = sample\n",
    "#del train\n",
    "#del enc_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/model.pkl','rb') as f :\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.63      0.60       511\n",
      "          1       0.57      0.51      0.54       489\n",
      "\n",
      "avg / total       0.57      0.57      0.57      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print classification_report(y_true=y_test, y_pred=pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, Y, ratio=0.1):\n",
    "    test_ids = np.random.randint(0, X.shape[0], int(X.shape[0] * ratio))\n",
    "    x_test = X[test_ids]\n",
    "    y_test = Y[test_ids]\n",
    "    x_train = np.delete(X, test_ids, axis=0)\n",
    "    y_train = Y.drop(test_ids)\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "x_train, x_test, y_train, y_test = split_data(enc_train, target, .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.4, eval_metric='error', gamma=0,\n",
       "       learning_rate=0.2, max_delta_step=0, max_depth=1,\n",
       "       min_child_weight=7, missing=None, n_estimators=100, n_jobs=4,\n",
       "       nthread=None, objective='binary:logistic', random_state=2,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=0.4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(\n",
    "\tobjective = 'binary:logistic',\n",
    "\tn_jobs = 4,\n",
    "\trandom_state = seed,\n",
    "\teval_metric = \"error\",\n",
    "\t#-------\n",
    "\tmax_depth = 1,\n",
    "\tmin_child_weight = 7,\n",
    "\t#----------\n",
    "\tgamma = 0,\n",
    "\t#----------\n",
    "\tsubsample = 0.4,\n",
    "\tcolsample_bytree = 0.4,\n",
    "\t#------------\n",
    "\tscale_pos_weight = 1,\n",
    "\t#-----------\n",
    "\treg_alpha = 0,\n",
    "\treg_lambda = 1,\n",
    "\t#------------\n",
    "\tlearning_rate = 0.2\n",
    "\n",
    "\t#n_estimators = 1000,\n",
    "\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[CV] reg_alpha=0, reg_lambda=1 .......................................\n",
      "[CV] reg_alpha=0, reg_lambda=1 .......................................\n",
      "[CV] reg_alpha=0, reg_lambda=1 .......................................\n",
      "[CV] reg_alpha=1e-07, reg_lambda=1 ...................................\n",
      "[CV] ........ reg_alpha=0, reg_lambda=1, score=0.590582, total=  11.9s\n",
      "[CV] reg_alpha=1e-07, reg_lambda=1 ...................................\n",
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:   12.1s\n",
      "[CV] ........ reg_alpha=0, reg_lambda=1, score=0.583083, total=  12.8s\n",
      "[CV] ........ reg_alpha=0, reg_lambda=1, score=0.584334, total=  12.8s\n",
      "[CV] reg_alpha=1e-07, reg_lambda=1 ...................................\n",
      "[Parallel(n_jobs=4)]: Done   2 tasks      | elapsed:   13.1s\n",
      "[Parallel(n_jobs=4)]: Done   3 tasks      | elapsed:   13.2s\n",
      "[CV] reg_alpha=1e-05, reg_lambda=1 ...................................\n",
      "[CV] .... reg_alpha=1e-07, reg_lambda=1, score=0.590582, total=  13.4s\n",
      "[CV] reg_alpha=1e-05, reg_lambda=1 ...................................\n",
      "[Parallel(n_jobs=4)]: Done   4 tasks      | elapsed:   14.0s\n",
      "[CV] .... reg_alpha=1e-07, reg_lambda=1, score=0.584334, total=  11.7s\n",
      "[CV] reg_alpha=1e-05, reg_lambda=1 ...................................\n",
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:   25.1s\n",
      "[CV] .... reg_alpha=1e-07, reg_lambda=1, score=0.583083, total=  13.0s\n",
      "[CV] .... reg_alpha=1e-05, reg_lambda=1, score=0.590582, total=  11.9s\n",
      "[CV] reg_alpha=1e-06, reg_lambda=1 ...................................\n",
      "[Parallel(n_jobs=4)]: Done   6 tasks      | elapsed:   25.3s\n",
      "[Parallel(n_jobs=4)]: Done   7 tasks      | elapsed:   25.4s\n",
      "[CV] reg_alpha=1e-06, reg_lambda=1 ...................................\n",
      "[CV] .... reg_alpha=1e-05, reg_lambda=1, score=0.583083, total=  12.9s\n",
      "[Parallel(n_jobs=4)]: Done   8 tasks      | elapsed:   27.1s\n",
      "[CV] reg_alpha=1e-06, reg_lambda=1 ...................................\n",
      "[CV] .... reg_alpha=1e-06, reg_lambda=1, score=0.590582, total=  12.0s\n",
      "[Parallel(n_jobs=4)]: Done   9 tasks      | elapsed:   37.6s\n",
      "[CV] .... reg_alpha=1e-06, reg_lambda=1, score=0.583083, total=  12.1s\n",
      "[CV] .... reg_alpha=1e-05, reg_lambda=1, score=0.584334, total=  12.5s\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  12 | elapsed:   37.8s remaining:    7.6s\n",
      "[CV] .... reg_alpha=1e-06, reg_lambda=1, score=0.584334, total=  10.7s\n",
      "[Parallel(n_jobs=4)]: Done  12 out of  12 | elapsed:   38.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  12 out of  12 | elapsed:   38.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.4, eval_metric='error', gamma=0,\n",
       "       learning_rate=0.2, max_delta_step=0, max_depth=1,\n",
       "       min_child_weight=7, missing=None, n_estimators=100, n_jobs=4,\n",
       "       nthread=None, objective='binary:logistic', random_state=2,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=0.4),\n",
       "       fit_params={}, iid=True, n_jobs=4,\n",
       "       param_grid={'reg_alpha': [0, 1e-07, 1e-05, 1e-06], 'reg_lambda': [1]},\n",
       "       pre_dispatch=4, refit=True, return_train_score=True, scoring=None,\n",
       "       verbose=50)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'std_train_score': array([ 0.00133943,  0.00133943,  0.00133943,  0.00133943]), 'rank_test_score': array([1, 1, 1, 1], dtype=int32), 'mean_score_time': array([ 0.08148066,  0.06799142,  0.05314795,  0.03784609]), 'param_reg_lambda': masked_array(data = [1 1 1 1],\n",
      "             mask = [False False False False],\n",
      "       fill_value = ?)\n",
      ", 'std_test_score': array([ 0.00328032,  0.00328032,  0.00328032,  0.00328032]), 'param_reg_alpha': masked_array(data = [0 1e-07 1e-05 1e-06],\n",
      "             mask = [False False False False],\n",
      "       fill_value = ?)\n",
      ", 'split1_train_score': array([ 0.60231023,  0.60231023,  0.60231023,  0.60231023]), 'split0_test_score': array([ 0.59058188,  0.59058188,  0.59058188,  0.59058188]), 'mean_test_score': array([ 0.586,  0.586,  0.586,  0.586]), 'split2_train_score': array([ 0.60467906,  0.60467906,  0.60467906,  0.60467906]), 'split0_train_score': array([ 0.60546055,  0.60546055,  0.60546055,  0.60546055]), 'params': ({'reg_alpha': 0, 'reg_lambda': 1}, {'reg_alpha': 1e-07, 'reg_lambda': 1}, {'reg_alpha': 1e-05, 'reg_lambda': 1}, {'reg_alpha': 1e-06, 'reg_lambda': 1}), 'std_fit_time': array([ 0.39374109,  0.72603507,  0.38472434,  0.63366205]), 'std_score_time': array([ 0.04202183,  0.01370111,  0.01472793,  0.0185456 ]), 'split2_test_score': array([ 0.58433373,  0.58433373,  0.58433373,  0.58433373]), 'mean_train_score': array([ 0.60414995,  0.60414995,  0.60414995,  0.60414995]), 'mean_fit_time': array([ 12.39675768,  12.61427363,  12.37681135,  11.54432535]), 'split1_test_score': array([ 0.58308338,  0.58308338,  0.58308338,  0.58308338])} \n",
      "{'reg_alpha': 0, 'reg_lambda': 1} \n",
      "0.586\n"
     ]
    }
   ],
   "source": [
    "GS_params1 ={\n",
    "\t'max_depth':range(3,10,2),\n",
    "\t'min_child_weight':range(3,10,2)\n",
    "}\n",
    "GS_params2 ={\n",
    "\t'max_depth':[1,2,3],\n",
    "    'min_child_weight':[7]\n",
    "}\n",
    "\n",
    "GS_params3 ={\n",
    "\t'gamma':[i/10.0 for i in range(0,5)]\n",
    "}\n",
    "GS_params4 = {\n",
    " 'subsample':[i/10.0 for i in range(1,6)],\n",
    " 'colsample_bytree':[i/10.0 for i in range(1,6)]\n",
    "}\n",
    "GS_params5 = {\n",
    " 'subsample':[.35,.4,.45],\n",
    " 'colsample_bytree':[.35,.4,.45]\n",
    "}\n",
    "GS_params6 = {\n",
    " 'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100],\n",
    " 'reg_lambda':[1e-5, 1e-2, 0.1, 1, 100]\n",
    "}\n",
    "GS_params7 = {\n",
    "'reg_alpha':[0, 1e-7, 1e-5 ,1e-6],\n",
    " 'reg_lambda':[1]\n",
    "}\n",
    "\n",
    "gsearch = GridSearchCV(model, param_grid = GS_params7,n_jobs=4,pre_dispatch=4, cv=3, verbose=50 )\n",
    "gsearch.fit(enc_train, target)\n",
    "print gsearch.cv_results_, '\\n' ,gsearch.best_params_,'\\n' ,gsearch.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/model.pkl', 'wb') as f:\n",
    "    pickle.dump(file=f, obj=model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
